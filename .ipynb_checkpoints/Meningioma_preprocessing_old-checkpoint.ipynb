{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing brain MRI of patients with meningioma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before using MONSTR\n",
    "\n",
    "### Setting PATH variable\n",
    "**The environment PATH MUST be set in the main terminal, not otherwise like in a sub-terminal in the Jupyterlab**\n",
    "\n",
    "#### ANTs\n",
    "export ANTSPATH=/opt/ANTs/bin/\n",
    "\n",
    "export PATH=${ANTSPATH}:$PATH\n",
    "\n",
    "#### FSL\n",
    "FSLDIR=/usr/local/fsl\n",
    ". ${FSLDIR}/etc/fslconf/fsl.sh\n",
    "\n",
    "PATH=${FSLDIR}/bin:${PATH}\n",
    "\n",
    "export FSLDIR PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## below are previous codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcDir = \n",
    "    print(\"N4 bias correction: \", pt)\n",
    "    correctionDir = os.path.join(targetDir, \"correction\")\n",
    "    \n",
    "    if not os.path.exists(correctionDir):\n",
    "        os.makedirs(correctionDir)\n",
    "                          \n",
    "    for file in os.listdir(resampleDir):\n",
    "        filePath = os.path.join(resampleDir, pt, file)\n",
    "        \n",
    "        if not os.path.exists(os.path.join(correctionDir, pt)):\n",
    "            os.makedirs(os.path.join(correctionDir, pt))\n",
    "            \n",
    "        outPath = os.path.join(correctionDir, pt, file)\n",
    "        #!ResampleImage 3 {filePath} {outPath} 1x1x1\n",
    "        print(filePath, outPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for (BB, T2, WB) in zip(T1_BB, T2, T1_WB):\n",
    "    # patient ID number (MRN) is extracted as a variable 'mrn'\n",
    "    mrn = BB.split('_')[0] \n",
    "    print((BB, T2, WB))\n",
    "     print(\"<<< Started working on the following case: \", mrn, \" >>>\")\n",
    "        \n",
    "    # 0. Copy the current T1 and T2 files onto the working directory \n",
    "    #    (to avoid 'sudo' problem in trying to write a file on an external storage)\n",
    "    pathList = []\n",
    "    for file in os.listdir(patientDir):\n",
    "        shutil.copyfile(os.path.join(patientDir, file), os.path.join(workingDir, file))\n",
    "        pathList.append(os.path.join(workingDir, file))\n",
    "    \n",
    "    # 1. Resampling onto 1mm x 1mm x 1mm images \n",
    "    print(\"1) Resampling to 1-mm isovoxel images: \", end=\"\")\n",
    "    for file in pathList:\n",
    "        !ResampleImage 3 {file} {file} 1x1x1\n",
    "        print(file, end=\"  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "##########metastasis for PYW ###########3\n",
    "\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# we'll work in the MONSTR directory\n",
    "workingDir = '/home/chansik/MONSTR'\n",
    "%cd {workingDir} \n",
    "\n",
    "# set paths for source and target\n",
    "sourceDir = '/media/chansik/Samsung_T5/mets_nifti'\n",
    "targetDir = '/media/chansik/Samsung_T5/mets_stripped'\n",
    "outputPath = '/home/chansik/MONSTR/output'\n",
    "##########################################################################################\n",
    "\n",
    "alreadyDoneList = []\n",
    "\n",
    "# file names MUST be BB.nii, WB.nii, T2.nii, FLAIR.nii, and ADC.nii\n",
    "\n",
    "for patient in os.listdir(sourceDir):\n",
    "    patientDir = os.path.join(sourceDir, patient)\n",
    "    \n",
    "    # check if preprocessing has already been done\n",
    "    # if so, skip the patient and move onto the next patient\n",
    "    if patient in os.listdir(targetDir):\n",
    "        print(patient, 'has already been processed!')\n",
    "        alreadyDoneList.append(patient)\n",
    "        continue\n",
    "    \n",
    "    print(\"<<< Started working on the following case: \", patient, \" >>>\")\n",
    "    \n",
    "    # 0. Copy the current T1 and T2 files onto the working directory \n",
    "    #    (to avoid 'sudo' problem in trying to write a file on an external storage)\n",
    "    pathList = []\n",
    "    for file in os.listdir(patientDir):\n",
    "        shutil.copyfile(os.path.join(patientDir, file), os.path.join(workingDir, file))\n",
    "        pathList.append(os.path.join(workingDir, file))\n",
    "    \n",
    "    # 1. Resampling onto 1mm x 1mm x 1mm images \n",
    "    print(\"1) Resampling to 1-mm isovoxel images: \", end=\"\")\n",
    "    for file in pathList:\n",
    "        !ResampleImage 3 {file} {file} 1x1x1\n",
    "        print(file, end=\"  \")\n",
    "    \n",
    "    # 2. N4 bias correction\n",
    "    # by using ANTs, using the same parameters as the default one used by MONSTR\n",
    "    print(\"\\n2) N4 bias field correction: \", end=\"\")\n",
    "    for file in pathList:\n",
    "        !N4BiasFieldCorrection -d 3 -i {file} -o {file} -s 3 -c [50x50x50x50,0.00001] -b [150]\n",
    "        print(file, end=\"  \")\n",
    "  \n",
    "    # 3. Co-registration\n",
    "    # by using ANTs, using the same parameters as the default one used by MONSTR\n",
    "    print(\"\\n3) Co-registration with CE-T1 images as fixed, reference images: \", end=\"\")\n",
    "    for file in [\"T2.nii\", \"WB.nii\"]:\n",
    "        newName = file.split(\".\")[0] + \"_registered.nii\"\n",
    "        !antsRegistration -d 3 -r [BB.nii, {file}, 1] \\\n",
    "                          -m mattes[BB.nii, {file}, 1, 32, regular, 0.1 ] \\\n",
    "                          -t translation[0.1] -c [100x50x25,1.e-8,20] -s 4x2x1vox -f 6x4x2 -l 1 \\\n",
    "                          -m mattes[BB.nii, {file} , 1 , 32, regular, 0.1] \\\n",
    "                          -t rigid[0.1] -c [100x50x25,1.e-8,20]  -s 4x2x1vox  -f 3x2x1 -l 1 -o [reg, {newName}] -v 0\n",
    "        print(file, end=\"  \")\n",
    "    shutil.copyfile(\"BB.nii\", \"BB_registered.nii\")\n",
    " \n",
    "    # 4. MONSTR skull stripping\n",
    "    t1 = \"WB_registered.nii\"\n",
    "    t2 = \"T2_registered.nii\"\n",
    "    !./MONSTR.sh --t1 {t1} --t2 {t2} --o output --atlasdir TBI_atlas --reg\n",
    "\n",
    "    # Copy the relevant files (brain Mask and processed images)\n",
    "    createdDir = os.path.join(outputPath, os.listdir(outputPath)[0])\n",
    "\n",
    "    os.makedirs(os.path.join(targetDir, patient))\n",
    "    for file in os.listdir(createdDir):\n",
    "        if file == 'atlas4_brainmask_ANTS.nii.gz':\n",
    "            newFileName = patient + '/brain_mask.nii.gz'\n",
    "            shutil.copyfile(os.path.join(createdDir, file), os.path.join(targetDir, newFileName))\n",
    "\n",
    "    shutil.copyfile(\"WB_registered.nii\", os.path.join(targetDir, patient, \"WB_registered.nii\"))\n",
    "    shutil.copyfile(\"BB_registered.nii\", os.path.join(targetDir, patient, \"BB_registered.nii\"))\n",
    "    shutil.copyfile(\"T2_registered.nii\", os.path.join(targetDir, patient, \"T2_registered.nii\"))\n",
    " \n",
    "    # 5. Clean the temporarily created files and directories\n",
    "    shutil.rmtree(createdDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceDir = '/media/chansik/Samsung_T5/test'\n",
    "targetDir = '/media/chansik/Samsung_T5/mets_stripped'\n",
    "outputPath = '/home/chansik/MONSTR/output'\n",
    "\n",
    "# Copy the relevant files (brain Mask and processed images)\n",
    "createdDir = os.path.join(outputPath, os.listdir(outputPath)[0])\n",
    "patient = '1234'\n",
    "\n",
    "os.makedirs(os.path.join(targetDir, patient))\n",
    "for file in os.listdir(createdDir):\n",
    "    if file == 'atlas4_brainmask_ANTS.nii.gz':\n",
    "        newFileName = patient + '/brain_mask.nii.gz'\n",
    "        shutil.copyfile(os.path.join(createdDir, file), os.path.join(targetDir, newFileName))\n",
    "    \n",
    "shutil.copyfile(\"WB_registered.nii\", os.path.join(targetDir, patient, \"WB_registered.nii\"))\n",
    "shutil.copyfile(\"BB_registered.nii\", os.path.join(targetDir, patient, \"BB_registered.nii\"))\n",
    "shutil.copyfile(\"T2_registered.nii\", os.path.join(targetDir, patient, \"T2_registered.nii\"))\n",
    "\n",
    "# Clean the temporarily created files and directories\n",
    "#os.remove(os.path.join(workingDir, t1))\n",
    "#os.remove(os.path.join(workingDir, t2))\n",
    "#shutil.rmtree(createdDir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = \"BB_registered.nii\"\n",
    "t2 = \"T2_registered.nii\"\n",
    "\n",
    "!./MONSTR.sh --t1 {t1} --t2 {t2} --o output --atlasdir TBI_atlas --reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " !./MONSTR.sh --t1 {t1} --t2 {t2} --o output --atlasdir TBI_atlas --reg\n",
    "\n",
    "    # 3. Copy the relevant files (brain Mask and processed T1/T2 images)\n",
    "    createdDir = os.path.join(outputPath, os.listdir(outputPath)[0])\n",
    "\n",
    "    for file in os.listdir(createdDir):\n",
    "        if file == 'atlas4_brainmask_ANTS.nii.gz':\n",
    "            newFileName = mrn + '_bMask.nii.gz'\n",
    "            shutil.copyfile(os.path.join(createdDir, file), os.path.join(targetDir, newFileName))\n",
    "\n",
    "        if file == 't1.nii.gz':\n",
    "            newFileName = mrn + '_T1GD_processed.nii.gz'\n",
    "            shutil.copyfile(os.path.join(createdDir, file), os.path.join(targetDir, newFileName))\n",
    "\n",
    "        if file == 't2.nii.gz':\n",
    "            newFileName = mrn + '_T2_processed.nii.gz'\n",
    "            shutil.copyfile(os.path.join(createdDir, file), os.path.join(targetDir, newFileName))\n",
    "\n",
    "    # 4. Clean the temporarily created files and directories\n",
    "    os.remove(os.path.join(workingDir, t1))\n",
    "    os.remove(os.path.join(workingDir, t2))\n",
    "    shutil.rmtree(createdDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "##########test ###########3\n",
    "\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# we'll work in the MONSTR directory\n",
    "workingDir = '/home/chansik/MONSTR'\n",
    "%cd {workingDir} \n",
    "\n",
    "# set paths for source and target\n",
    "sourceDir = '/media/chansik/Samsung_T5'\n",
    "targetDir = '/media/chansik/SC_research_2019/GBM-Surv/Seg_results'\n",
    "##########################################################################################\n",
    "\n",
    "alreadyDoneList = []\n",
    "\n",
    "# file names MUST be CE-T1.nii, UE-T1.nii, T2.nii, FLAIR.nii, and ADC.nii\n",
    "\n",
    "for patient in os.listdir(sourceDir):\n",
    "    patientDir = os.path.join(sourceDir, patient)\n",
    "    \n",
    "    # check if preprocessing has already been done\n",
    "    # if so, skip the patient and move onto the next patient\n",
    "    if patient in os.listdir(targetDir):\n",
    "        print(patient, 'has already been processed!')\n",
    "        alreadyDoneList.append(patient)\n",
    "        continue\n",
    "    \n",
    "    print(\"<<< Started working on the following case: \", patient, \" >>>\")\n",
    "    \n",
    "    # 0. Copy the current T1 and T2 files onto the working directory \n",
    "    #    (to avoid 'sudo' problem in trying to write a file on an external storage)\n",
    "    pathList = []\n",
    "    for file in os.listdir(patientDir):\n",
    "        shutil.copyfile(os.path.join(patientDir, file), os.path.join(workingDir, file))\n",
    "        pathList.append(os.path.join(workingDir, file))\n",
    "    \n",
    "    # 1. Resampling onto 1mm x 1mm x 1mm images \n",
    "    print(\"1) Resampling to 1-mm isovoxel images: \", end=\"\")\n",
    "    for file in pathList:\n",
    "        !ResampleImage 3 {file} {file} 1x1x1\n",
    "        print(file, end=\"  \")\n",
    "    \n",
    "    # 2. N4 bias correction\n",
    "    # by using ANTs, using the same parameters as the default one used by MONSTR\n",
    "    print(\"\\n2) N4 bias field correction: \", end=\"\")\n",
    "    for file in pathList:\n",
    "        !N4BiasFieldCorrection -d 3 -i {file} -o {file} -s 3 -c [50x50x50x50,0.00001] -b [150]\n",
    "        print(file, end=\"  \")\n",
    "  \n",
    "    # 3. Co-registration\n",
    "    # by using ANTs, using the same parameters as the default one used by MONSTR\n",
    "    print(\"\\n3) Co-registration with CE-T1 images as fixed, reference images: \", end=\"\")\n",
    "    for file in [\"UE-T1.nii\", \"T2.nii\", \"FLAIR.nii\", \"ADC.nii\"]:\n",
    "        newName = file.split(\".\")[0] + \"_registered.nii\"\n",
    "        !antsRegistration -d 3 -r [CE-T1.nii, {file}, 1] \\\n",
    "                          -m mattes[CE-T1.nii, {file}, 1, 32, regular, 0.1 ] \\\n",
    "                          -t translation[0.1] -c [100x50x25,1.e-8,20] -s 4x2x1vox -f 6x4x2 -l 1 \\\n",
    "                          -m mattes[CE-T1.nii, {file} , 1 , 32, regular, 0.1] \\\n",
    "                          -t rigid[0.1] -c [100x50x25,1.e-8,20]  -s 4x2x1vox  -f 3x2x1 -l 1 -o [reg, {newName}] -v 0\n",
    "        print(file, end=\"  \")\n",
    "    shutil.copyfile(\"CE-T1.nii\", \"CE-T1_registered.nii\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # check if preprocessing has already been done\n",
    "    # if so, skip the patient and move onto the next patient\n",
    "    if mrn in [i.split('_', 1)[0] for i in os.listdir(targetDir)]:\n",
    "        print(mrn, 'has already been processed!')\n",
    "        alreadyDoneList.append(mrn)\n",
    "        continue\n",
    "       \n",
    "    # 0. Copy the current T1 and T2 files onto the working directory \n",
    "    #    (to avoid 'sudo' problem in trying to write a file on an external storage)\n",
    "    shutil.copyfile(os.path.join(sourceDir, t1), os.path.join(workingDir, t1))\n",
    "    shutil.copyfile(os.path.join(sourceDir, t2), os.path.join(workingDir, t2))\n",
    "    \n",
    "    # 1. Resampling of CE-T1-weighted images onto 1mm x 1mm x 1mm images \n",
    "    #   (as some T1 images are 2D)\n",
    "    !ResampleImage 3 {t1} {t1} 1x1x1 \n",
    "    \n",
    "    # 2. Skull stripping by MONSTR algorithm following \n",
    "    #          1) rigid coregistration of T2 onto T1 (ANTs)\n",
    "    #          2) N4 bias correction (ANTs)\n",
    "    !./MONSTR.sh --t1 {t1} --t2 {t2} --o output --atlasdir TBI_atlas \n",
    "\n",
    "    # 3. Copy the relevant files (brain Mask and processed T1/T2 images)\n",
    "    createdDir = os.path.join(outputPath, os.listdir(outputPath)[0])\n",
    "\n",
    "    for file in os.listdir(createdDir):\n",
    "        if file == 'atlas4_brainmask_ANTS.nii.gz':\n",
    "            newFileName = mrn + '_bMask.nii.gz'\n",
    "            shutil.copyfile(os.path.join(createdDir, file), os.path.join(targetDir, newFileName))\n",
    "\n",
    "        if file == 't1.nii.gz':\n",
    "            newFileName = mrn + '_T1GD_processed.nii.gz'\n",
    "            shutil.copyfile(os.path.join(createdDir, file), os.path.join(targetDir, newFileName))\n",
    "\n",
    "        if file == 't2.nii.gz':\n",
    "            newFileName = mrn + '_T2_processed.nii.gz'\n",
    "            shutil.copyfile(os.path.join(createdDir, file), os.path.join(targetDir, newFileName))\n",
    "\n",
    "    # 4. Clean the temporarily created files and directories\n",
    "    os.remove(os.path.join(workingDir, t1))\n",
    "    os.remove(os.path.join(workingDir, t2))\n",
    "    shutil.rmtree(createdDir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workingDir = '/home/chansik/MONSTR'\n",
    "%cd {workingDir} \n",
    "shutil.copyfile(\"CE-T1.nii\", \"CE-T1_registered.nii\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workingDir = '/home/chansik/MONSTR'\n",
    "%cd {workingDir} \n",
    "\n",
    "!./MONSTR.sh --t1 CE-T1_registered.nii --t2 T2_registered.nii --fl FLAIR_registered.nii --o output --atlasdir TBI_atlas --reg --clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import nibabel as nib\n",
    "#import matplotlib.pyplot as plt\n",
    "#from matplotlib.image import imsave\n",
    "#from PIL import Image\n",
    "\n",
    "workingDir = '/home/chansik/MONSTR'\n",
    "%cd {workingDir} \n",
    "\n",
    "mask_array = nib.load(\"atlas4_brainmask_ANTS.nii.gz\").get_fdata()\n",
    "    \n",
    "for file in [\"UE-T1_registered.nii\", \"CE-T1_registered.nii\", \"T2_registered.nii\", \"FLAIR_registered.nii\", \"ADC_registered.nii\"]:\n",
    "    img_array = nib.load(file).get_fdata()\n",
    "    stripped_array = img_array * mask_array\n",
    "    \n",
    "    newName = file.split(\".\")[0].split(\"_\")[0] + \"_stripped.nii\"\n",
    "    \n",
    "    niftiFile = nib.Nifti1Image(stripped_array, np.eye(4)) \n",
    "    nib.save(niftiFile, newName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"UE-T1_registered.nii\"\n",
    "file.split(\".\")[0].split(\"_\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    \n",
    "    # 2. Skull stripping by MONSTR algorithm following \n",
    "    #          1) rigid coregistration of T2 onto T1 (ANTs)\n",
    "    #          2) N4 bias correction (ANTs)\n",
    "    !./MONSTR.sh --t1 {t1} --t2 {t2} --o output --atlasdir TBI_atlas \n",
    "\n",
    "    # 3. Copy the relevant files (brain Mask and processed T1/T2 images)\n",
    "    createdDir = os.path.join(outputPath, os.listdir(outputPath)[0])\n",
    "\n",
    "    for file in os.listdir(createdDir):\n",
    "        if file == 'atlas4_brainmask_ANTS.nii.gz':\n",
    "            newFileName = mrn + '_bMask.nii.gz'\n",
    "            shutil.copyfile(os.path.join(createdDir, file), os.path.join(targetDir, newFileName))\n",
    "\n",
    "        if file == 't1.nii.gz':\n",
    "            newFileName = mrn + '_T1GD_processed.nii.gz'\n",
    "            shutil.copyfile(os.path.join(createdDir, file), os.path.join(targetDir, newFileName))\n",
    "\n",
    "        if file == 't2.nii.gz':\n",
    "            newFileName = mrn + '_T2_processed.nii.gz'\n",
    "            shutil.copyfile(os.path.join(createdDir, file), os.path.join(targetDir, newFileName))\n",
    "\n",
    "    # 4. Clean the temporarily created files and directories\n",
    "    os.remove(os.path.join(workingDir, t1))\n",
    "    os.remove(os.path.join(workingDir, t2))\n",
    "    shutil.rmtree(createdDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # 4. MONSTR skull stripping\n",
    "    t1 = \"WB_registered.nii\"\n",
    "    t2 = \"T2_registered.nii\"\n",
    "    \n",
    "\n",
    "    # Copy the relevant files (brain Mask and processed images)\n",
    "    \n",
    "\n",
    "    shutil.copyfile(\"WB_registered.nii\", os.path.join(targetDir, patient, \"WB_registered.nii\"))\n",
    "    shutil.copyfile(\"BB_registered.nii\", os.path.join(targetDir, patient, \"BB_registered.nii\"))\n",
    "    shutil.copyfile(\"T2_registered.nii\", os.path.join(targetDir, patient, \"T2_registered.nii\"))\n",
    " \n",
    "    # 5. Clean the temporarily created files and directories\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## centering, cropping, and selecting slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function\n",
    "\n",
    "def center_crop(img, margin=10):\n",
    "    # convert an image into an sqaure image if the dimensions of x and y are different\n",
    "    if img.shape[0] != img.shape[1]:\n",
    "        if img.shape[0] < img.shape[1]:\n",
    "            pad_width = int((img.shape[1] - img.shape[0])//2)\n",
    "            img = np.pad(img, ((pad_width, pad_width), (0,0), (0,0)), constant_values=0)\n",
    "\n",
    "        if img.shape[0] > img.shape[1]:\n",
    "            pad_width = int((img.shape[0] - img.shape[1])//2)\n",
    "            img = np.pad(img, ((0,0), (pad_width, pad_width), (0,0)), constant_values=0)\n",
    "        \n",
    "    # calculate the non-zero margins of x and y axes.\n",
    "    x_min, x_max = 1000, 0\n",
    "    y_min, y_max = 1000, 0\n",
    "\n",
    "    for z in range(img.shape[2]):\n",
    "        for row in range(img.shape[0]):\n",
    "            x = np.nonzero(img[row, :, z])\n",
    "\n",
    "            if x[0].size == 0:\n",
    "                continue\n",
    "\n",
    "            if x_min > x[0].min():\n",
    "                x_min = x[0].min()\n",
    "            if x_max < x[0].max():\n",
    "                x_max = x[0].max()\n",
    "\n",
    "        for col in range(img.shape[1]):\n",
    "            y = np.nonzero(img[:, col, z])\n",
    "\n",
    "            if y[0].size == 0:\n",
    "                continue\n",
    "\n",
    "            if y_min > y[0].min():\n",
    "                y_min = y[0].min()\n",
    "            if y_max < y[0].max():\n",
    "                y_max = y[0].max()\n",
    "\n",
    "    x_width = x_max - x_min\n",
    "    x_center = x_min + (x_width//2)\n",
    "    y_width = y_max - y_min\n",
    "    y_center = y_min + (y_width//2)\n",
    "\n",
    "    if x_width >= y_width:\n",
    "        new_width = x_width + margin\n",
    "    else: \n",
    "        new_width = y_width + margin\n",
    "\n",
    "    x_start, x_end = x_center-(new_width//2), x_center+(new_width//2)\n",
    "    y_start, y_end = y_center-(new_width//2), y_center+(new_width//2)\n",
    "\n",
    "    new_img = img[y_start:y_end, x_start:x_end, :]\n",
    "    \n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imsave\n",
    "from PIL import Image\n",
    "\n",
    "sourceDir = '/media/chansik/SC_research_2019/GBM-Surv/ProcessedByMONSTR'\n",
    "outputDir = '/home/chansik/DataAnalysis/201912-GBM-Surv/output-multiple'\n",
    "\n",
    "range_df = pd.read_csv('/home/chansik/DataAnalysis/201912-GBM-Surv/input/range_list.csv', header=None)\n",
    "\n",
    "target_img_size = (224, 224)\n",
    "\n",
    "for idx, row in range_df.iterrows():\n",
    "    t1_name = os.path.join(sourceDir, (str(row[0]) + \"_T1GD_processed.nii.gz\"))\n",
    "    t2_name = os.path.join(sourceDir, (str(row[0]) + \"_T2_processed.nii.gz\"))\n",
    "    mask_name = os.path.join(sourceDir, (str(row[0]) + \"_bMask.nii.gz\"))\n",
    "    \n",
    "    # Get Image Array (numpy array) from Nifti File\n",
    "    t1_array = nib.load(t1_name).get_fdata()\n",
    "    t2_array = nib.load(t2_name).get_fdata()\n",
    "    mask_array = nib.load(mask_name).get_fdata()\n",
    "    \n",
    "    t1_img = t1_array * mask_array\n",
    "    t1_img = t1_img[:, :, int(row[1]):int(row[2])]\n",
    "    \n",
    "    t2_img = t2_array * mask_array\n",
    "    t2_img = t2_img[:, :, int(row[1]):int(row[2])]\n",
    "    \n",
    "    cropped_t1 = center_crop(t1_img, margin=10) # the function 'center_crop' was defined above\n",
    "    cropped_t2 = center_crop(t2_img, margin=10)\n",
    "    \n",
    "    height = int(row[2]) - int(row[1])\n",
    "    \n",
    "    for slc in range(2, height, 5):\n",
    "        selected_t1 = cropped_t1[:, :, slc]\n",
    "        selected_t2 = cropped_t2[:, :, slc]\n",
    "        \n",
    "        newT1name = os.path.join(outputDir, (str(row[0]) + \"_T1_\" + str(slc) + \".png\"))\n",
    "        newT2name = os.path.join(outputDir, (str(row[0]) + \"_T2_\" + str(slc) + \".png\"))\n",
    "\n",
    "        imsave(newT1name, selected_t1, cmap='gray')\n",
    "        imsave(newT2name, selected_t2, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## resizing and stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "baseDir = '/home/chansik/DataAnalysis/201912-GBM-Surv'\n",
    "sourceDir = os.path.join(baseDir, 'output-multiple')\n",
    "targetDir = os.path.join(baseDir, 'cnn_input')\n",
    "\n",
    "df = pd.read_csv(os.path.join(baseDir, 'input/GBM-surv-list.csv'))\n",
    "df = df.loc[df.death==1, ['ID', 'survival']]\n",
    "\n",
    "short = df.loc[df.survival < df.survival.median(), 'ID'].tolist()\n",
    "long = df.loc[df.survival >= df.survival.median(), 'ID'].tolist()\n",
    "\n",
    "short_validation_list = random.choices(short, k=30)\n",
    "long_validation_list = random.choices(long, k=30)\n",
    "\n",
    "for file in os.listdir(sourceDir):\n",
    "    \n",
    "    # patient ID number (MRN) is extracted as a variable 'mrn'\n",
    "    mrn = int(file.split('_', 1)[0])\n",
    "    \n",
    "    if mrn in short:\n",
    "        if mrn in short_validation_list:\n",
    "            shutil.copyfile(os.path.join(sourceDir, file), \n",
    "                            os.path.join(targetDir, 'validation/short', file))\n",
    "        else:\n",
    "             shutil.copyfile(os.path.join(sourceDir, file), \n",
    "                            os.path.join(targetDir, 'train/short', file))\n",
    "    \n",
    "    if mrn in long:\n",
    "        if mrn in long_validation_list:\n",
    "            shutil.copyfile(os.path.join(sourceDir, file), \n",
    "                            os.path.join(targetDir, 'validation/long', file))\n",
    "        else:\n",
    "             shutil.copyfile(os.path.join(sourceDir, file), \n",
    "                            os.path.join(targetDir, 'train/long', file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(sourceDir):\n",
    "    \n",
    "    # patient ID number (MRN) is extracted as a variable 'mrn'\n",
    "    mrn = int(file.split('_', 1)[0])\n",
    "    \n",
    "    if mrn in df.ID.tolist():\n",
    "        survival = df.loc[df.ID==mrn, 'survival'].values[0]\n",
    "        new_fileName = str(survival) + \"_\" + str(mrn) + \".png\"\n",
    "\n",
    "        if mrn in validation_set:\n",
    "            shutil.copyfile(os.path.join(sourceDir, file), \n",
    "                            os.path.join(targetDir, 'validation', new_fileName))\n",
    "        else:\n",
    "            shutil.copyfile(os.path.join(sourceDir, file), \n",
    "                            os.path.join(targetDir, 'train', new_fileName))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseDir = '/home/chansik/DataAnalysis/201912-GBM-Surv'\n",
    "sourceDir = os.path.join(baseDir, 'output')\n",
    "targetDir = os.path.join(baseDir, 'cnn_regression')\n",
    "\n",
    "[p.split('_')[os.listdir(targetDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### divide patients into two: short and long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "df = pd.read_csv('/home/chansik/DataAnalysis/201912-GBM-Surv/input/GBM-surv-list.csv')\n",
    "df = df.loc[df.death==1, ['ID', 'survival']]\n",
    "\n",
    "short = df.loc[df.survival < df.survival.median(), 'ID'].tolist()\n",
    "long = df.loc[df.survival >= df.survival.median(), 'ID'].tolist()\n",
    "\n",
    "sourceDir = '/home/chansik/DataAnalysis/201912-GBM-Surv/output'\n",
    "shortDir = '/home/chansik/DataAnalysis/201912-GBM-Surv/cnn_input/short'\n",
    "longDir = '/home/chansik/DataAnalysis/201912-GBM-Surv/cnn_input/long'\n",
    "\n",
    "for file in os.listdir(sourceDir):\n",
    "    \n",
    "    # patient ID number (MRN) is extracted as a variable 'mrn'\n",
    "    mrn = int(file.split('_', 1)[0])\n",
    "\n",
    "    if mrn in short:\n",
    "        shutil.copyfile(os.path.join(sourceDir, file), os.path.join(shortDir, file))\n",
    "    if mrn in long:\n",
    "        shutil.copyfile(os.path.join(sourceDir, file), os.path.join(longDir, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert gray to RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from matplotlib.image import imsave\n",
    "\n",
    "baseDir = '/home/chansik/DataAnalysis/201912-GBM-Surv'\n",
    "print(os.path.join(baseDir, 'output'))\n",
    "for file in os.listdir(os.path.join(baseDir, 'output')):\n",
    "    final_img_name = os.path.join(baseDir, 'gray-to-rgb', file)\n",
    "    converted = tf.image.grayscale_to_rgb(file, name=None)\n",
    "    imsave(final_img_name, converted)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "resized_image = Image.fromarray(new_img[:,:,20]).resize((224, 224))\n",
    "\n",
    "nifti_file = nib.Nifti1Image(new_img, np.eye(4))\n",
    "nib.save(nifti_file, 'test.nii') # Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.array(resized_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img[:, :, 29])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img.shape)\n",
    "new = np.pad(img, pad_width = ((1,1), (0,0), (0,0)), constant_values=0)\n",
    "print(new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imsave\n",
    "from PIL import Image\n",
    "\n",
    "image_array = nib.load(\"251020_T1GD_processed.nii.gz\").get_fdata()\n",
    "mask_array = nib.load(\"251020_bMask.nii.gz\").get_fdata()\n",
    "img = image_array * mask_array\n",
    "img = img[:, :, 53:113]\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
